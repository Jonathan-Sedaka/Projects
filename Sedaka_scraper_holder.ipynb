{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 for GS failed. Retrying...\n",
      "Failed to scrape data for GS: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"#Col1-0-Profile-Proxy > section > section.Bxz\\(bb\\).quote-subsection.undefined > table > tbody\"}\n",
      "  (Session info: chrome=121.0.6167.184); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010529a538 chromedriver + 4687160\n",
      "1   chromedriver                        0x0000000105291d83 chromedriver + 4652419\n",
      "2   chromedriver                        0x0000000104e82fbd chromedriver + 397245\n",
      "3   chromedriver                        0x0000000104ecec3c chromedriver + 707644\n",
      "4   chromedriver                        0x0000000104ecee11 chromedriver + 708113\n",
      "5   chromedriver                        0x0000000104f13274 chromedriver + 987764\n",
      "6   chromedriver                        0x0000000104ef192d chromedriver + 850221\n",
      "7   chromedriver                        0x0000000104f107bc chromedriver + 976828\n",
      "8   chromedriver                        0x0000000104ef16a3 chromedriver + 849571\n",
      "9   chromedriver                        0x0000000104ec117f chromedriver + 651647\n",
      "10  chromedriver                        0x0000000104ec215e chromedriver + 655710\n",
      "11  chromedriver                        0x000000010525a980 chromedriver + 4426112\n",
      "12  chromedriver                        0x000000010525fc18 chromedriver + 4447256\n",
      "13  chromedriver                        0x000000010523ee81 chromedriver + 4312705\n",
      "14  chromedriver                        0x0000000105260966 chromedriver + 4450662\n",
      "15  chromedriver                        0x0000000105230c9c chromedriver + 4254876\n",
      "16  chromedriver                        0x0000000105280528 chromedriver + 4580648\n",
      "17  chromedriver                        0x00000001052806de chromedriver + 4581086\n",
      "18  chromedriver                        0x00000001052919c3 chromedriver + 4651459\n",
      "19  libsystem_pthread.dylib             0x00007fff203c48fc _pthread_start + 224\n",
      "20  libsystem_pthread.dylib             0x00007fff203c0443 thread_start + 15\n",
      "\n",
      "Attempt 1 for MS failed. Retrying...\n",
      "Attempt 1 for C failed. Retrying...\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def extract_data_with_retry(symbol, css_selector, retries=5, delay=6):\n",
    "    for attempt in range(retries):\n",
    "        driver = webdriver.Chrome()\n",
    "        profile_url = f'https://finance.yahoo.com/quote/{symbol}/profile'\n",
    "        driver.get(profile_url)\n",
    "        time.sleep(13)  \n",
    "        try:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, css_selector).text\n",
    "            driver.quit()\n",
    "            return element\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Attempt {attempt + 1} for {symbol} failed\")\n",
    "            driver.quit()\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(5)\n",
    "    raise NoSuchElementException(f\"Failed to find element after {retries} attempts for {symbol}\")\n",
    "\n",
    "def scrape_stock_profile(symbol):\n",
    "    company_name = extract_data_with_retry(symbol, '#Col1-0-Profile-Proxy > section > div.asset-profile-container > div > h3')\n",
    "    address = extract_data_with_retry(symbol, '#Col1-0-Profile-Proxy > section > div.asset-profile-container > div > div > p.D\\\\(ib\\\\).W\\\\(47\\\\.727\\\\%\\\\).Pend\\\\(40px\\\\)')\n",
    "    description = extract_data_with_retry(symbol, '#Col1-0-Profile-Proxy > section > section.quote-sub-section.Mt\\\\(30px\\\\) > p')\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(f'https://finance.yahoo.com/quote/{symbol}/profile')\n",
    "    time.sleep(13)\n",
    "    executives = []\n",
    "    try:\n",
    "        executives_table = driver.find_element(By.CSS_SELECTOR, '#Col1-0-Profile-Proxy > section > section.Bxz\\\\(bb\\\\).quote-subsection.undefined > table > tbody')\n",
    "        rows = executives_table.find_elements(By.TAG_NAME, 'tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "            if len(cols) > 1:\n",
    "                executives.append({\n",
    "                    'Name': cols[0].text.strip(),\n",
    "                    'Title': cols[1].text.strip()\n",
    "                })\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return {\n",
    "        'Symbol': symbol,\n",
    "        'Company Name': company_name,\n",
    "        'Address': address,\n",
    "        'Description': description,\n",
    "        'Executives': executives\n",
    "    }\n",
    "\n",
    "stocks = ['JPM', 'GS', 'MS', 'C', 'WFC']\n",
    "all_data = []\n",
    "\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        stock_profile = scrape_stock_profile(stock)\n",
    "        for executive in stock_profile['Executives']:\n",
    "            all_data.append({\n",
    "                'Symbol': stock_profile['Symbol'],\n",
    "                'Company Name': stock_profile['Company Name'],\n",
    "                'Address': stock_profile['Address'],\n",
    "                'Description': stock_profile['Description'],\n",
    "                'Executive Name': executive['Name'],\n",
    "                'Executive Title': executive['Title']\n",
    "            })\n",
    "    except NoSuchElementException as e:\n",
    "        print(f\"Failed to scrape data for {stock}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "csv_file_path = '/Users/jonathansedaka/Documents/DATA 580/multiple_stocks_profile_data.csv'\n",
    "excel_file_path = '/Users/jonathansedaka/Documents/DATA 580/multiple_stocks_profile_data.xlsx'\n",
    "json_file_path = '/Users/jonathansedaka/Documents/DATA 580/multiple_stocks_profile_data.json'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "df.to_json(json_file_path, orient='records', lines=True)\n",
    "\n",
    "print(\"YES\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
